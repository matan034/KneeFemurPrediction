{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matan034/KneeFemurPrediction/blob/main/KneeProject_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylZAVlS5lzLZ"
      },
      "source": [
        "#Predict\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZN6diklpPJuz"
      },
      "outputs": [],
      "source": [
        "# install required packages\n",
        "!pip install numpy-stl\n",
        "!pip install trimesh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9XGtR_olxU2"
      },
      "outputs": [],
      "source": [
        "import os,glob\n",
        "from google.colab import drive, files\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import cv2\n",
        "import nibabel as nib\n",
        "from stl import mesh\n",
        "import trimesh\n",
        "from datetime import datetime\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQU3Y3hFl9HB"
      },
      "outputs": [],
      "source": [
        "\n",
        "IMAGE_HEIGHT =  256\n",
        "IMAGE_WIDTH = 256\n",
        "IMG_SIZE = (IMAGE_HEIGHT, IMAGE_WIDTH)\n",
        "SCALE_FACTOR = 0.3\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "TRANSFER_LEARNING = True  # use attention unet with transfer learning\n",
        "CLASSIFIER = True         # use attention unet with a classifer\n",
        "EXTRA_LAYER = True        # use attention unet with extra layer\n",
        "USE_NII_FROM_DRIVE = True\n",
        "json_model_path = '/content/drive/MyDrive/KneeProject/Best results/Attention with everything/all_Attention-UNET_(256_256)_epochs:150_learning:0.0001_loss:Tver_batch:64.json'\n",
        "h5_model_path = '/content/drive/MyDrive/KneeProject/Best results/Attention with everything/all_Attention-UNET_(256_256)_epochs:150_learning:0.0001_loss:Tver_batch:64.h5'\n",
        "if USE_NII_FROM_DRIVE:\n",
        "  filename = '/content/drive/MyDrive/KneeProject/volume_data/'\n",
        "else:\n",
        "  uploaded = files.upload()\n",
        "  for file in uploaded:\n",
        "    filename = file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model architecture from JSON file\n",
        "with open(json_model_path, 'r') as json_file:\n",
        "    loaded_model_json = json_file.read()\n",
        "    loaded_model = tf.keras.models.model_from_json(loaded_model_json)\n",
        "\n",
        "# Load weights into loaded model\n",
        "loaded_model.load_weights(h5_model_path)\n",
        "\n",
        "model = loaded_model\n",
        "\n",
        "\n",
        "print('Model loaded from disk.')"
      ],
      "metadata": {
        "id": "S5nSNcqDeXbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VOLUME_SLICE_X=True   # use X axis in prediction\n",
        "VOLUME_SLICE_Y=True   # use Y axis in prediction\n",
        "VOLUME_SLICE_Z=True   # use Z axis in prediction\n",
        "HOUNSFIELD_MIN = -1000\n",
        "HOUNSFIELD_MAX = 2000\n",
        "HOUNSFIELD_RANGE = HOUNSFIELD_MAX - HOUNSFIELD_MIN\n",
        "\n",
        "def scaleImg(img, height, width):\n",
        "    return cv2.resize(img, dsize=(width, height), interpolation=cv2.INTER_LINEAR)\n",
        "\n",
        "# Normalize image\n",
        "def normalizeImageIntensityRange(img):\n",
        "    img[img < HOUNSFIELD_MIN] = HOUNSFIELD_MIN\n",
        "    img[img > HOUNSFIELD_MAX] = HOUNSFIELD_MAX\n",
        "    return (img - HOUNSFIELD_MIN) / HOUNSFIELD_RANGE\n",
        "\n",
        "def predictVolume(inImg, toBin=True):\n",
        "    (xMax, yMax, zMax) = inImg.shape\n",
        "\n",
        "    outImgX = np.zeros((xMax, yMax, zMax))\n",
        "    outImgY = np.zeros((xMax, yMax, zMax))\n",
        "    outImgZ = np.zeros((xMax, yMax, zMax))\n",
        "\n",
        "    cnt = 0.0\n",
        "    if VOLUME_SLICE_X:\n",
        "        cnt += 1.0\n",
        "        for i in range(xMax):\n",
        "            img = inImg[i,:,:]\n",
        "            img = scaleImg(img, IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n",
        "            if TRANSFER_LEARNING or CLASSIFIER:\n",
        "              img = np.repeat(img, 3, axis=3)\n",
        "            tmp = model.predict(img)[0,:,:,0]\n",
        "            outImgX[i,:,:] = scaleImg(tmp, yMax, zMax)\n",
        "    if VOLUME_SLICE_Y:\n",
        "        cnt += 1.0\n",
        "        for i in range(yMax):\n",
        "            img = scaleImg(inImg[:,i,:], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n",
        "            if TRANSFER_LEARNING or CLASSIFIER:\n",
        "              img = np.repeat(img, 3, axis=3)\n",
        "            tmp = model.predict(img)[0,:,:,0]\n",
        "            outImgY[:,i,:] = scaleImg(tmp, xMax, zMax)\n",
        "    if VOLUME_SLICE_Z:\n",
        "        cnt += 1.0\n",
        "        for i in range(zMax):\n",
        "            img = scaleImg(inImg[:,:,i], IMAGE_HEIGHT, IMAGE_WIDTH)[np.newaxis,:,:,np.newaxis]\n",
        "            if TRANSFER_LEARNING or CLASSIFIER:\n",
        "              img = np.repeat(img, 3, axis=3)\n",
        "            tmp = model.predict(img)[0,:,:,0]\n",
        "            outImgZ[:,:,i] = scaleImg(tmp, xMax, yMax)\n",
        "\n",
        "    outImg = (outImgX + outImgY + outImgZ)/cnt\n",
        "    if(toBin):\n",
        "        outImg[outImg>0.5] = 1.0\n",
        "        outImg[outImg<=0.5] = 0.0\n",
        "    return outImg"
      ],
      "metadata": {
        "id": "TMAE2ETKectg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imgTargetNii = nib.load(filename)\n",
        "# Get the image data as a 3D array\n",
        "img_data = imgTargetNii.get_fdata()\n",
        "imgTarget = normalizeImageIntensityRange(img_data)\n",
        "predImg = predictVolume(imgTarget)"
      ],
      "metadata": {
        "id": "NoYWm51cla0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vertices, faces, _, _ = measure.marching_cubes(predImg)\n",
        "\n",
        "affine_matrix = imgTargetNii.affine\n",
        "\n",
        "\n",
        "# Add a homogeneous coordinate (1) to each vertex to make the matrix multiplication possible\n",
        "homogeneous_vertices = np.hstack((vertices, np.ones((len(vertices), 1))))\n",
        "\n",
        "# Apply the affine transformation\n",
        "vertices = np.dot(homogeneous_vertices, affine_matrix.T)[:, :3]  # Only keep the x, y, z coordinates\n",
        "reflection_matrix = np.array([[-1, 0, 0],\n",
        "                              [0, -1, 0],\n",
        "                              [0, 0, 1]])\n",
        "\n",
        "# Apply the reflection to the mesh vertices\n",
        "vertices = np.dot(vertices, reflection_matrix)\n",
        "knee_mesh=trimesh.Trimesh(vertices,faces)\n",
        "knee_mesh=trimesh.smoothing.filter_laplacian(knee_mesh,0.5,20)\n",
        "\n",
        "timestamp = datetime.now()\n",
        "mesh_path = f'knee-segmented{timestamp}.stl'\n",
        "knee_mesh.export(mesh_path)\n",
        "\n",
        "files.download(mesh_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "u-gGPu7Ief4Z",
        "outputId": "a0312906-b008-479c-aa8b-40c08b065624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d5ffa614-5912-4add-8324-a1fdd358f727\", \"knee-segmented2023-07-27 10:43:53.798169.stl\", 30439684)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "gpuClass": "premium",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}